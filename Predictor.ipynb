{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# To get run time for each cell\n",
        "!pip install ipython-autotime -q\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYCkJUR_t_bZ",
        "outputId": "0c08b358-61cd-4d72-a640-18b0c310c0c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n",
            "time: 2.21 s (started: 2024-09-27 10:11:00 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhTtgogRtcrr",
        "outputId": "7cb01f26-e885-49ab-cb62-124df0c6abf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:02:01 --:--:--     0^C\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:06 --:--:--     0^C\n",
            "time: 2min 8s (started: 2024-09-27 10:11:03 +00:00)\n"
          ]
        }
      ],
      "source": [
        "url = 'https://anaconda.org/conda-forge/libta-lib/0.4.0/download/linux-64/libta-lib-0.4.0-h166bdaf_1.tar.bz2'\n",
        "!curl -L $url | tar xj -C /usr/lib/x86_64-linux-gnu/ lib --strip-components=1\n",
        "url = 'https://anaconda.org/conda-forge/ta-lib/0.4.19/download/linux-64/ta-lib-0.4.19-py310hde88566_4.tar.bz2'\n",
        "!curl -L $url | tar xj -C /usr/local/lib/python3.10/dist-packages/ lib/python3.10/site-packages/talib --strip-components=3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Pytorch Library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.cuda as cuda\n",
        "import talib\n",
        "import math\n",
        "\n",
        "# Utility Libraries\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n"
      ],
      "metadata": {
        "id": "elvr6pZDuAbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d70cfe4-0f5f-4d10-9894-f894494f21fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.28 ms (started: 2024-09-27 10:18:25 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate technical indicators\n",
        "def calculate_technical_indicators(df, normalise=False):\n",
        "\n",
        "    # Normalise the data if needed\n",
        "    if normalise:\n",
        "        x = df.values\n",
        "        standard_scaler = StandardScaler()\n",
        "        x_scaled = standard_scaler.fit_transform(x)\n",
        "        df = pd.DataFrame(x_scaled, columns=df.columns)\n",
        "\n",
        "    # Calculate technical indicators using TA-Lib\n",
        "    df['RSI'] = talib.RSI(df['close'], 20)\n",
        "\n",
        "    upper, middle, lower = talib.BBANDS(df['close'], timeperiod=20, nbdevup=2, nbdevdn=2)\n",
        "    df['BBANDS_Upper'] = upper\n",
        "    df['BBANDS_Middle'] = middle\n",
        "    df['BBANDS_Lower'] = lower\n",
        "\n",
        "    macd, signal, hist = talib.MACD(df['close'], fastperiod=3, slowperiod=18, signalperiod=6)\n",
        "    df['MACD'] = macd\n",
        "    df['SIGNAL'] = signal\n",
        "    df['HIST'] = hist\n",
        "\n",
        "    df['OBV'] = talib.OBV(df['close'], df['volume'])\n",
        "    df['EMA'] = talib.EMA(df['close'], timeperiod=20)\n",
        "\n",
        "    df['ATR'] = talib.ATR(df['high'], df['low'], df['close'], timeperiod=14)\n",
        "    df['CCI'] = talib.CCI(df['high'], df['low'], df['close'], timeperiod=14)\n",
        "    df['ROC'] = talib.ROC(df['close'], timeperiod=10)\n",
        "    df['WILLR'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=14)\n",
        "\n",
        "    df = df[23:].reset_index(drop=True)\n",
        "    return df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVr-1ymbuHsj",
        "outputId": "e0204bca-9617-42de-9b2a-f290f839acf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.4 ms (started: 2024-09-27 10:18:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to prepare training and testing data\n",
        "def prepare_train_test_data(df, days_input, days_output, train_split, normalise=False, shuffle=False):\n",
        "\n",
        "    # Compute the difference between consecutive data points\n",
        "    # df = df.diff().dropna().reset_index(drop=True)\n",
        "\n",
        "    # Normalise the data if needed\n",
        "    if normalise:\n",
        "        x = df.values\n",
        "        standard_scaler = StandardScaler()\n",
        "        x_scaled = standard_scaler.fit_transform(x)\n",
        "        df = pd.DataFrame(x_scaled, columns=df.columns)\n",
        "\n",
        "    # Split data into training and testing\n",
        "    train_indices = int(df.shape[0] * train_split)\n",
        "    train_data = df[:train_indices]\n",
        "    test_data = df[train_indices:]\n",
        "    test_data = test_data.reset_index(drop=True)\n",
        "\n",
        "    # Get the train and test Y\n",
        "    train_y = df['close'][:train_indices]\n",
        "    test_y = df['close'][train_indices:]\n",
        "    test_y = test_y.reset_index(drop=True)\n",
        "\n",
        "    train_sequences_X = [train_data[i: i + days_input].values for i in range(0, len(train_data) - (days_input + days_output - 1))]\n",
        "    train_sequences_y = [train_y[i: i + days_output] for i in range(days_input, len(train_y) - (days_output - 1))]\n",
        "    test_sequences_X = [test_data[i: i + days_input].values for i in range(0, len(test_data) - (days_input + days_output - 1))]\n",
        "    test_sequences_y = [test_y[i: i + days_output] for i in range(days_input, len(test_y) - (days_output - 1))]\n",
        "\n",
        "    # Split data into sequences\n",
        "    if not shuffle:\n",
        "        train_sequences_X = np.array(train_sequences_X)\n",
        "        train_sequences_y = np.array(train_sequences_y)\n",
        "        test_sequences_X = np.array(test_sequences_X)\n",
        "        test_sequences_y = np.array(test_sequences_y)\n",
        "\n",
        "        return train_sequences_X, train_sequences_y, test_sequences_X, test_sequences_y, test_data\n",
        "\n",
        "    # Shuffle data\n",
        "    indices = np.random.permutation(len(train_sequences_X))\n",
        "    X_train = np.array([train_sequences_X[i] for i in indices])\n",
        "    y_train = np.array([train_sequences_y[i] for i in indices])\n",
        "\n",
        "    return X_train, y_train, np.array(test_sequences_X), np.array(test_sequences_y), test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYO9NniEuP6B",
        "outputId": "3fdd1027-12ff-4140-cfe6-dfa337496287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.66 ms (started: 2024-09-27 10:18:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the csv_files list with this function\n",
        "def get_csv_files(folder_path):\n",
        "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
        "    return [os.path.join(folder_path, f) for f in csv_files]\n",
        "\n",
        "# Function to assign trend signs to an array\n",
        "# def assign_trend_sign(arr):\n",
        "#     trend_signs = np.sign(arr)  # Get signs of all values\n",
        "#     trend_signs[trend_signs > 0] = 1  # Map positive values to 1\n",
        "#     trend_signs[trend_signs < 0] = -1  # Map negative values to -1\n",
        "#     return trend_signs\n",
        "\n",
        "def assign_trend_sign(arr):\n",
        "    trend_signs = np.zeros_like(arr)  # Initialize an array of zeros with the same shape as arr\n",
        "    trend_signs[1:] = np.sign(arr[1:] - arr[:-1])  # Compare each element with the previous one\n",
        "    return trend_signs\n",
        "\n",
        "# Function to count matching elements in two arrays\n",
        "def count_matching_elements(arr1, arr2):\n",
        "    if arr1.shape != arr2.shape:\n",
        "        raise ValueError(\"Input arrays must have the same shape\")\n",
        "\n",
        "    matching_count = np.sum(arr1 == arr2)\n",
        "    total_elements = np.prod(arr1.shape)  # Total number of elements in the array\n",
        "    matching_percentage = (matching_count / total_elements) * 100  # Calculate percentage\n",
        "\n",
        "    return matching_percentage\n",
        "\n",
        "def calculate_sharpe_ratio(returns, risk_free_rate=0.02):\n",
        "    excess_returns = returns - risk_free_rate\n",
        "    return np.sqrt(252) * excess_returns.mean() / excess_returns.std()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIR0J_qSuqcm",
        "outputId": "fcda8704-b95a-457e-a859-756215aafaf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.98 ms (started: 2024-09-27 10:18:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch.nn as nn\n",
        "\n",
        "class PositionalEncodingCNN(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncodingCNN, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.d_model = d_model\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Expand the positional encoding to match the input shape\n",
        "        batch_size, features, seq_len = x.size()\n",
        "        pe = self.pe\n",
        "        pe = pe.permute(2, 1, 0)\n",
        "        pe = pe[:,:,:seq_len]\n",
        "        pe_1 = pe.repeat(1, features +1, 1)\n",
        "        # print(f\"X shape: {x.shape}\")\n",
        "        # print(f\"PE shape: {pe.shape}\")\n",
        "        x = torch.cat((x, pe), dim=1)\n",
        "        x = x + pe_1\n",
        "        return self.dropout(x)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POb7nliYDk7d",
        "outputId": "d0093d07-ffc5-4816-9425-bd688749df93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 870 µs (started: 2024-09-27 10:18:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, kernel_sizes, batch_size, stride=1, dilation=1, activation=nn.ReLU(), num_heads=8, dropout_rate=0.2):\n",
        "        super(ConvBlock, self).__init__()\n",
        "\n",
        "        # Convolution layers\n",
        "        self.conv_layers = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels, hidden_channels, kernel_size, stride=stride, padding=\"same\", dilation=dilation)\n",
        "            for kernel_size in kernel_sizes\n",
        "        ])\n",
        "\n",
        "        # Batch layer for Convolution Layer\n",
        "        self.bn_layers = nn.ModuleList([nn.BatchNorm1d(hidden_channels) for _ in kernel_sizes])\n",
        "\n",
        "        # Positional Encoder\n",
        "        self.pos_encoder = PositionalEncodingCNN(batch_size, dropout_rate)\n",
        "\n",
        "        # MLP + Batch Normal layer\n",
        "        self.mlp = nn.Conv1d((hidden_channels * len(kernel_sizes)) + 1, out_channels, kernel_size=1)\n",
        "        self.bn_final = nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        # Activation Layer\n",
        "        self.activation = activation\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Transposing the input to match the time dimension\n",
        "        input = input.transpose(1, 2)\n",
        "\n",
        "        # Taking all of the convolutions and concatenating them\n",
        "        conv_outputs = [bn(conv(input)) for conv, bn in zip(self.conv_layers, self.bn_layers)]\n",
        "        total_conv = torch.cat(conv_outputs, dim=1)\n",
        "\n",
        "        # print(f\"PE input{total_conv.shape}\")\n",
        "\n",
        "        # Apply Positional Encoder\n",
        "        total_conv = self.pos_encoder(total_conv)\n",
        "        # print(f\"PE output{total_conv.shape}\")\n",
        "\n",
        "        # Applying the final convolution to change the number of features\n",
        "        output = self.mlp(total_conv)\n",
        "\n",
        "        output = self.bn_final(output)\n",
        "\n",
        "        # Activation\n",
        "        # output = self.activation(output)\n",
        "\n",
        "        output = output.transpose(1, 2)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXgaa3KDueLg",
        "outputId": "6c4fe9b3-9ace-4f35-fd8d-d6036e2dd1f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 808 µs (started: 2024-09-27 10:18:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "\n",
        "# class TransformerWithAttention(nn.Module):\n",
        "#     def __init__(self, input_size, hidden_size, hidden_size2, seq_len, num_layers, num_heads, dropout_rate=0.3):\n",
        "#         super(TransformerWithAttention, self).__init__()\n",
        "\n",
        "#         self.input_size = input_size\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.seq_len = seq_len\n",
        "#         self.num_layers = num_layers\n",
        "#         self.num_heads = num_heads\n",
        "\n",
        "#         # Input embedding\n",
        "#         self.input_embedding = nn.Linear(input_size, hidden_size)\n",
        "\n",
        "#         # Positional encoding\n",
        "#         self.positional_encoding = PositionalEncoding(hidden_size, dropout_rate, seq_len)\n",
        "\n",
        "#         # Transformer Encoder 1\n",
        "#         encoder_layer1 = nn.TransformerEncoderLayer(d_model=hidden_size,\n",
        "#                                                     nhead=num_heads,\n",
        "#                                                     dim_feedforward=hidden_size * 4,\n",
        "#                                                     dropout=dropout_rate,\n",
        "#                                                     activation='gelu',\n",
        "#                                                     batch_first=True)\n",
        "#         self.transformer_encoder1 = nn.TransformerEncoder(encoder_layer1, num_layers=num_layers)\n",
        "\n",
        "#         # Transformer Encoder 2\n",
        "#         encoder_layer2 = nn.TransformerEncoderLayer(d_model=hidden_size,\n",
        "#                                                     nhead=num_heads,\n",
        "#                                                     dim_feedforward=hidden_size * 4,\n",
        "#                                                     dropout=dropout_rate,\n",
        "#                                                     activation='gelu',\n",
        "#                                                     batch_first=True)\n",
        "#         self.transformer_encoder2 = nn.TransformerEncoder(encoder_layer2, num_layers=num_layers)\n",
        "\n",
        "#         # Transformer Encoder 3\n",
        "#         encoder_layer3 = nn.TransformerEncoderLayer(d_model=hidden_size,\n",
        "#                                                     nhead=num_heads,\n",
        "#                                                     dim_feedforward=hidden_size * 4,\n",
        "#                                                     dropout=dropout_rate,\n",
        "#                                                     activation='gelu',\n",
        "#                                                     batch_first=True)\n",
        "#         self.transformer_encoder3 = nn.TransformerEncoder(encoder_layer3, num_layers=num_layers)\n",
        "\n",
        "#         # Multi-Head Attention between Encoder and Decoder layers\n",
        "#         self.multihead_attention1 = nn.MultiheadAttention(embed_dim=hidden_size, num_heads=num_heads, batch_first=True)\n",
        "#         self.multihead_attention2 = nn.MultiheadAttention(embed_dim=hidden_size, num_heads=num_heads, batch_first=True)\n",
        "#         self.multihead_attention3 = nn.MultiheadAttention(embed_dim=hidden_size, num_heads=num_heads, batch_first=True)\n",
        "\n",
        "#         # Transformer Decoder 1\n",
        "#         decoder_layer1 = nn.TransformerDecoderLayer(d_model=hidden_size,\n",
        "#                                                     nhead=num_heads,\n",
        "#                                                     dim_feedforward=hidden_size * 4,\n",
        "#                                                     dropout=dropout_rate,\n",
        "#                                                     activation='gelu',\n",
        "#                                                     batch_first=True)\n",
        "#         self.transformer_decoder1 = nn.TransformerDecoder(decoder_layer1, num_layers=num_layers)\n",
        "\n",
        "#         # Transformer Decoder 2\n",
        "#         decoder_layer2 = nn.TransformerDecoderLayer(d_model=hidden_size,\n",
        "#                                                     nhead=num_heads,\n",
        "#                                                     dim_feedforward=hidden_size * 4,\n",
        "#                                                     dropout=dropout_rate,\n",
        "#                                                     activation='gelu',\n",
        "#                                                     batch_first=True)\n",
        "#         self.transformer_decoder2 = nn.TransformerDecoder(decoder_layer2, num_layers=num_layers)\n",
        "\n",
        "#         # Transformer Decoder 3\n",
        "#         decoder_layer3 = nn.TransformerDecoderLayer(d_model=hidden_size,\n",
        "#                                                     nhead=num_heads,\n",
        "#                                                     dim_feedforward=hidden_size * 4,\n",
        "#                                                     dropout=dropout_rate,\n",
        "#                                                     activation='gelu',\n",
        "#                                                     batch_first=True)\n",
        "#         self.transformer_decoder3 = nn.TransformerDecoder(decoder_layer3, num_layers=num_layers)\n",
        "\n",
        "#         # Output layer\n",
        "#         self.output_layer = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "#         # Normalization layers\n",
        "#         self.norm_hidden = nn.LayerNorm(hidden_size)\n",
        "#         self.norm_output = nn.LayerNorm(input_size)\n",
        "\n",
        "#         # GELU and dropout layers\n",
        "#         self.gelu = nn.GELU()\n",
        "#         self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "#     def forward(self, input):\n",
        "#         # Input embedding\n",
        "#         embedded_input = self.input_embedding(input)\n",
        "\n",
        "#         # Positional encoding\n",
        "#         encoded_input = self.positional_encoding(embedded_input)\n",
        "\n",
        "#         # Transformer Encoder 1\n",
        "#         encoder_output1 = self.transformer_encoder1(encoded_input)\n",
        "#         encoder_output1 = self.norm_hidden(self.gelu(encoder_output1))\n",
        "\n",
        "#         # Multi-Head Attention 1\n",
        "#         attn_output1, _ = self.multihead_attention1(encoder_output1, encoder_output1, encoder_output1)\n",
        "#         attn_output1 = self.norm_hidden(self.gelu(attn_output1))\n",
        "\n",
        "#         # Transformer Encoder 2\n",
        "#         encoder_output2 = self.transformer_encoder2(attn_output1)\n",
        "#         encoder_output2 = self.norm_hidden(self.gelu(encoder_output2))\n",
        "\n",
        "#         # Multi-Head Attention 2\n",
        "#         attn_output2, _ = self.multihead_attention2(encoder_output2, encoder_output2, encoder_output2)\n",
        "#         attn_output2 = self.norm_hidden(self.gelu(attn_output2))\n",
        "\n",
        "#         # Transformer Encoder 3\n",
        "#         encoder_output3 = self.transformer_encoder3(attn_output2)\n",
        "#         encoder_output3 = self.norm_hidden(self.gelu(encoder_output3))\n",
        "\n",
        "#         # Multi-Head Attention 3\n",
        "#         attn_output3, _ = self.multihead_attention3(encoder_output3, encoder_output3, encoder_output3)\n",
        "#         attn_output3 = self.norm_hidden(self.gelu(attn_output3))\n",
        "\n",
        "#         # Transformer Decoder 1\n",
        "#         decoder_output1 = self.transformer_decoder1(attn_output3, attn_output3)\n",
        "#         decoder_output1 = self.norm_hidden(self.gelu(decoder_output1))\n",
        "\n",
        "#         # Transformer Decoder 2\n",
        "#         decoder_output2 = self.transformer_decoder2(decoder_output1, decoder_output1)\n",
        "#         decoder_output2 = self.norm_hidden(self.gelu(decoder_output2))\n",
        "\n",
        "#         # Transformer Decoder 3\n",
        "#         decoder_output3 = self.transformer_decoder3(decoder_output2, decoder_output2)\n",
        "#         decoder_output3 = self.norm_hidden(self.gelu(decoder_output3))\n",
        "\n",
        "#         # Output processing\n",
        "#         output = self.output_layer(decoder_output3)\n",
        "#         output = self.norm_output(output)\n",
        "\n",
        "#         # Return only the last time step prediction\n",
        "#         return output[:, -1, :]\n",
        "\n",
        "# # Positional Encoding Class remains unchanged\n",
        "# class PositionalEncoding(nn.Module):\n",
        "#     def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "#         super(PositionalEncoding, self).__init__()\n",
        "#         self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "#         pe = torch.zeros(max_len, d_model)\n",
        "#         position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "#         div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "#         pe[:, 0::2] = torch.sin(position * div_term)\n",
        "#         pe[:, 1::2] = torch.cos(position * div_term)\n",
        "#         pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "#         self.register_buffer('pe', pe)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = x + self.pe[:x.size(0), :]\n",
        "#         return self.dropout(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyK4Kd2Yfj8M",
        "outputId": "1a88ef25-67d7-4ebd-b945-63c1da0565b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 249 µs (started: 2024-09-27 10:18:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, hidden_size, num_heads, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.mha = nn.MultiheadAttention(hidden_size, num_heads, dropout=dropout_rate, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.mha(x, x, x, need_weights=False)[0]\n",
        "\n",
        "class CrossAttention(nn.Module):\n",
        "    def __init__(self, hidden_size, num_heads, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.mha = nn.MultiheadAttention(hidden_size, num_heads, dropout=dropout_rate, batch_first=True)\n",
        "\n",
        "    def forward(self, x, context):\n",
        "        return self.mha(x, x, context, need_weights=False)[0]\n",
        "\n",
        "class TransformerWithAttention(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, hidden_size2, seq_len, num_layers, num_heads, dropout_rate=0.3):\n",
        "        super(TransformerWithAttention, self).__init__()\n",
        "\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.seq_len = seq_len\n",
        "        self.num_layers = num_layers\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        # Input embedding\n",
        "        self.input_embedding = nn.Linear(input_size, hidden_size)\n",
        "\n",
        "        # Positional encoding\n",
        "        self.positional_encoding = PositionalEncoding(hidden_size, dropout_rate, seq_len)\n",
        "\n",
        "        # Transformer Encoders and Self-Attention\n",
        "        self.transformer_encoders = nn.ModuleList([\n",
        "            nn.TransformerEncoderLayer(d_model=hidden_size,\n",
        "                                       nhead=num_heads,\n",
        "                                       dim_feedforward=hidden_size * 4,\n",
        "                                       dropout=dropout_rate,\n",
        "                                       activation='gelu',\n",
        "                                       batch_first=True)\n",
        "            for _ in range(3)\n",
        "        ])\n",
        "        self.self_attentions = nn.ModuleList([\n",
        "            SelfAttention(hidden_size, num_heads, dropout_rate)\n",
        "            for _ in range(2)  # One less than encoder layers\n",
        "        ])\n",
        "\n",
        "        # Multi-Head Attention layers\n",
        "        self.multihead_attentions = nn.ModuleList([\n",
        "            nn.MultiheadAttention(embed_dim=hidden_size, num_heads=num_heads, batch_first=True)\n",
        "            for _ in range(5)\n",
        "        ])\n",
        "\n",
        "        # Transformer Decoders and Cross-Attention\n",
        "        self.transformer_decoders = nn.ModuleList([\n",
        "            nn.TransformerDecoderLayer(d_model=hidden_size,\n",
        "                                       nhead=num_heads,\n",
        "                                       dim_feedforward=hidden_size * 4,\n",
        "                                       dropout=dropout_rate,\n",
        "                                       activation='gelu',\n",
        "                                       batch_first=True)\n",
        "            for _ in range(3)\n",
        "        ])\n",
        "        self.cross_attentions = nn.ModuleList([\n",
        "            CrossAttention(hidden_size, num_heads, dropout_rate)\n",
        "            for _ in range(2)  # One less than decoder layers\n",
        "        ])\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "        # Normalization layers\n",
        "        self.norm_hidden = nn.LayerNorm(hidden_size)\n",
        "        self.norm_output = nn.LayerNorm(input_size)\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Input embedding\n",
        "        x = self.input_embedding(input)\n",
        "\n",
        "        # Positional encoding\n",
        "        layer_0 = self.positional_encoding(x)\n",
        "\n",
        "        # Transformer Encoder 1\n",
        "        layer_1 = self.transformer_encoders[0](layer_0)\n",
        "        layer_1 = self.norm_hidden(layer_1)\n",
        "\n",
        "        # Self-Attention 1\n",
        "        self_attn_1 = self.self_attentions[0](layer_1)\n",
        "        self_attn_1 = self.norm_hidden(self_attn_1)\n",
        "\n",
        "        # Transformer Encoder 2\n",
        "        layer_2 = self.transformer_encoders[1](self_attn_1)\n",
        "        layer_2 = self.norm_hidden(layer_2)\n",
        "\n",
        "        # Self-Attention 2\n",
        "        self_attn_2 = self.self_attentions[1](layer_2)\n",
        "        self_attn_2 = self.norm_hidden(self_attn_2)\n",
        "\n",
        "        # Transformer Encoder 3\n",
        "        layer_3 = self.transformer_encoders[2](self_attn_2)\n",
        "        layer_3 = self.norm_hidden(layer_3)\n",
        "\n",
        "        # Attention 3\n",
        "        attention_3, _ = self.multihead_attentions[2](layer_3, layer_3, layer_3)\n",
        "        attention_3 = self.norm_hidden(attention_3)\n",
        "\n",
        "        # Transformer Decoder 1\n",
        "        layer_3 = self.transformer_decoders[0](attention_3, attention_3)\n",
        "        layer_3 = self.norm_hidden(layer_3)\n",
        "\n",
        "        # Cross-Attention 1\n",
        "        cross_attn_1 = self.cross_attentions[0](layer_3, self_attn_2)\n",
        "        cross_attn_1 = self.norm_hidden(cross_attn_1)\n",
        "\n",
        "        # Transformer Decoder 2\n",
        "        layer_2 = self.transformer_decoders[1](cross_attn_1, cross_attn_1)\n",
        "        layer_2 = self.norm_hidden(layer_2)\n",
        "\n",
        "        # Cross-Attention 2\n",
        "        cross_attn_2 = self.cross_attentions[1](layer_2, self_attn_1)\n",
        "        cross_attn_2 = self.norm_hidden(cross_attn_2)\n",
        "\n",
        "        # Transformer Decoder 3\n",
        "        layer_1 = self.transformer_decoders[2](cross_attn_2, cross_attn_2)\n",
        "        layer_1 = self.norm_hidden(layer_1)\n",
        "\n",
        "        # Output processing\n",
        "        output = self.output_layer(layer_1)\n",
        "        output = self.norm_output(output)\n",
        "\n",
        "        # Return only the last time step prediction\n",
        "        return output[:, -1, :]\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVOq1mxwr2Uz",
        "outputId": "38c4f86a-e122-4f8e-a5b9-e4e72b9e76d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.48 ms (started: 2024-09-27 10:18:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNLSTMWithSelfAttentionLNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size_1, hidden_size_2, hidden_size_3, hidden_size_4, lstm_layers, output_size, kernel_sizes, seq_len, num_days, batch_size, device, l2_lambda, dropout_rate=0.4, num_heads=16):\n",
        "        super(CNNLSTMWithSelfAttentionLNN, self).__init__()\n",
        "\n",
        "        # Backbone attribues\n",
        "        self.input_size = input_size\n",
        "        self.kernel_sizes = kernel_sizes\n",
        "        self.hidden_size_1 = hidden_size_1\n",
        "        self.hidden_size_2 = hidden_size_2\n",
        "        self.hidden_size_3 = hidden_size_3\n",
        "        self.hidden_size_4 = hidden_size_4\n",
        "        self.lstm_layers = lstm_layers\n",
        "        self.num_heads = num_heads\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Stock Data Attributes\n",
        "        self.seq_len = seq_len\n",
        "        self.num_days = num_days\n",
        "\n",
        "        # Dropout rate\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.l2_lambda = l2_lambda\n",
        "        self.batch_size = batch_size\n",
        "        self.device = device\n",
        "\n",
        "        # Hidden states\n",
        "        self.h = None\n",
        "        self.c = None\n",
        "\n",
        "        # Backbone models\n",
        "        self.conv_blocks = ConvBlock(self.input_size, self.hidden_size_1, self.hidden_size_2, self.kernel_sizes, self.batch_size, dropout_rate=self.dropout_rate)\n",
        "        # self.lstm_block = LSTMWithAttention(self.hidden_size_2, self.hidden_size_3, self.hidden_size_4, self.seq_len, self.lstm_layers, self.num_heads, dropout_rate=self.dropout_rate)\n",
        "        self.lstm_block = TransformerWithAttention(self.hidden_size_2, self.hidden_size_3, self.hidden_size_4, self.seq_len, self.lstm_layers, self.num_heads, dropout_rate=self.dropout_rate)\n",
        "\n",
        "        # Linear Model, RELU and dropout\n",
        "        self.fc = nn.Linear(hidden_size_2, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        self.h = torch.zeros(self.lstm_layers, batch_size, self.hidden_size_3).to(self.device)\n",
        "        self.c = torch.zeros(self.lstm_layers, batch_size, self.hidden_size_3).to(self.device)\n",
        "\n",
        "    def reset_hidden(self):\n",
        "        self.h = None\n",
        "        self.c = None\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # print(\"\\n******************** CONVOLUTION BLOCK ******************** \\n\\n\")\n",
        "\n",
        "        # Process input through the convolutional block\n",
        "        conv_output = self.conv_blocks(x)\n",
        "        # print(f\"Convolution output shape: {conv_output.shape}\")\n",
        "        # print(f\"Convolution output: {conv_output}\")\n",
        "\n",
        "        # print(\"******************** LSTM BLOCK ******************** \\n\\n\")\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # Initialize hidden states if not already done\n",
        "        if self.h is None or self.c is None or batch_size != self.h.size(1):\n",
        "            self.init_hidden(batch_size)\n",
        "\n",
        "        # Initialize the hidden state\n",
        "        h = self.h.detach()\n",
        "        c = self.c.detach()\n",
        "\n",
        "        # Initialize the prediction_tensor\n",
        "        predictions_tensor = torch.tensor([]).to(x.device)\n",
        "\n",
        "        # Loop through the sequence length\n",
        "        for i in range(self.num_days):\n",
        "\n",
        "          # print(f\"******************** Day {i+1} ******************** \\n\\n\")\n",
        "\n",
        "\n",
        "          # Process input through the LSTM with attention block\n",
        "          # lstm_output, h, c = self.lstm_block(conv_output[:, -self.seq_len:, :], h, c)\n",
        "          lstm_output= self.lstm_block(conv_output[:, -self.seq_len:, :])\n",
        "          # print(f\"LSTM output shape: {lstm_output.shape}\")\n",
        "          # print(f\"LSTM output: {lstm_output}\")\n",
        "\n",
        "\n",
        "          linear_output = self.fc(lstm_output)\n",
        "          # print(f\"Linear output shape: {linear_output.shape}\")\n",
        "          # print(f\"Linear output: {linear_output}\")\n",
        "\n",
        "          predictions_tensor = torch.cat((predictions_tensor, linear_output), dim=1)\n",
        "          # print(f\"Predictions tensor shape for day {i+1}: {predictions_tensor.shape}\")\n",
        "\n",
        "          conv_output = torch.cat((conv_output, lstm_output.unsqueeze(1)), dim=1)\n",
        "          # print(f\"Conv output shape for day {i+1}: {conv_output.shape}\")\n",
        "\n",
        "        # print(f\"Final predictions tensor shape: {predictions_tensor.shape}\")\n",
        "\n",
        "        self.h = h.detach()\n",
        "        self.c = c.detach()\n",
        "\n",
        "        return predictions_tensor[:, -1:]\n",
        "\n",
        "    def loss(self, outputs, labels):\n",
        "        # print(f\"Outputs shape: {outputs.shape}\")\n",
        "        # print(f\"Labels shape: {labels.shape}\")\n",
        "\n",
        "        # L2 regularisation\n",
        "        # l2_norm = sum(p.pow(2.0).sum() for p in self.parameters())\n",
        "        loss = nn.MSELoss()(outputs, labels )\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "rl_zlIp7uVkH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcbd6676-bfe8-423f-dc7b-4d96d0700a3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.24 ms (started: 2024-09-27 10:18:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train the model\n",
        "def train(model, train_dataset, val_dataset, optimizer, scheduler, epochs, batch_size, device, save_path=None):\n",
        "    model.to(device)\n",
        "\n",
        "    # Initialize the training and validation dataset\n",
        "    X_train, y_train = train_dataset\n",
        "    X_val, y_val = val_dataset\n",
        "    train_loss_total = []\n",
        "    val_loss_total = []\n",
        "    matching_elements = []\n",
        "    matching_elements_shifted = []\n",
        "\n",
        "    # Initialize the best_loss and num_batches\n",
        "    best_val_loss = float('inf')\n",
        "    num_batches = len(X_train) // batch_size\n",
        "\n",
        "    # Loop for traning rounds\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # # Reset hidden states at the beginning of each batch\n",
        "        # model.reset_hidden()\n",
        "\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        progress_bar = tqdm(range(num_batches), desc=f'Epoch {epoch+1}', unit='batch')\n",
        "\n",
        "        for batch_idx in progress_bar:\n",
        "\n",
        "            # Getting the start and end index\n",
        "            start_idx = batch_idx * batch_size\n",
        "            end_idx = start_idx + batch_size\n",
        "\n",
        "            # Getting the training batch\n",
        "            inputs = X_train[start_idx:end_idx, :, :].float().to(device)\n",
        "            labels = y_train[start_idx:end_idx, :].float().to(device)\n",
        "            # print(f\"Inputs shape: {inputs.shape}\")\n",
        "            # print(f\"Labels shape: {labels.shape})\n",
        "\n",
        "            # Traning the model for the epoch\n",
        "            outputs = model(inputs)\n",
        "            # print(f\"Output shape right out of the model: {outputs.shape}\")\n",
        "            loss = model.loss(outputs, labels)\n",
        "\n",
        "            # Backpropogation and updation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "\n",
        "            avg_loss = total_loss / (batch_idx + 1)\n",
        "            progress_bar.set_postfix(loss=avg_loss)\n",
        "\n",
        "        print(f\"Validating...\")\n",
        "\n",
        "        # Validate the model\n",
        "        val_loss = validate(model, val_dataset, batch_size, device)\n",
        "\n",
        "        # Changing the learning rate according to the loss\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Training Loss: {total_loss / num_batches}, Validation Loss: {val_loss}\\n')\n",
        "        train_loss_total.append(total_loss / num_batches)\n",
        "        val_loss_total.append(val_loss)\n",
        "\n",
        "        # Calculate matching elements\n",
        "        _, outputs, labels = test(model, val_dataset, batch_size, device)\n",
        "        outputs_np = outputs.cpu().numpy().flatten()\n",
        "        labels_np = labels.cpu().numpy().flatten()\n",
        "\n",
        "        array_output = assign_trend_sign(outputs_np)\n",
        "        array_labels = assign_trend_sign(labels_np)\n",
        "        matching = count_matching_elements(array_output, array_labels)\n",
        "        matching_elements.append(matching)\n",
        "\n",
        "        array_output_shifted = assign_trend_sign(np.roll(outputs_np, -1))\n",
        "        matching_shifted = count_matching_elements(array_output_shifted, array_labels)\n",
        "        matching_elements_shifted.append(matching_shifted)\n",
        "\n",
        "        # Save the model weights if the validation loss is the best we've seen so far.\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            if save_path:\n",
        "                torch.save(model.state_dict(), save_path)\n",
        "                print(f'Best model saved with validation loss: {best_val_loss:.4f}\\n')\n",
        "\n",
        "    return np.array(train_loss_total), np.array(val_loss_total), np.array(matching_elements), np.array(matching_elements_shifted)"
      ],
      "metadata": {
        "id": "jDuPE-iKuhvm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf482540-77d7-4a86-81c0-efb93faa7127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.17 ms (started: 2024-09-27 10:18:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to validate the model\n",
        "def validate(model, dataset, batch_size, device):\n",
        "\n",
        "    model.eval()\n",
        "    X_val, y_val = dataset\n",
        "\n",
        "    num_batches = len(X_val) // batch_size\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx in range(num_batches):\n",
        "\n",
        "\n",
        "            # Getting the start and end index\n",
        "            start_idx = batch_idx * batch_size\n",
        "            end_idx = start_idx + batch_size\n",
        "\n",
        "            # Getting the validation batch\n",
        "            inputs = X_val[start_idx:end_idx, :, :].float().to(device)\n",
        "            labels = y_val[start_idx:end_idx, :].float().to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            # print(outputs)\n",
        "            loss = model.loss(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "MxREZ5xeR00Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "336bf477-fe24-41c9-a5be-2fbf8208d5e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 530 µs (started: 2024-09-27 10:18:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to test the model\n",
        "def test(model, dataset, batch_size, device):\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    X_test, y_test = dataset\n",
        "\n",
        "    num_batches = len(X_test) // batch_size\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch_idx in range(num_batches):\n",
        "\n",
        "\n",
        "            # Getting the start and end index\n",
        "            start_idx = batch_idx * batch_size\n",
        "            end_idx = start_idx + batch_size\n",
        "\n",
        "            # Getting the validation batch\n",
        "            inputs = X_test[start_idx:end_idx, :, :].float().to(device)\n",
        "            labels = y_test[start_idx:end_idx, :].float().to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            # print(f\"Outputs shape: {outputs.shape}\")\n",
        "            # print(f\"Labels shape: {labels.shape}\")\n",
        "            loss = model.loss(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    print(f'Test Loss: {avg_loss}')\n",
        "    return avg_loss, outputs, labels"
      ],
      "metadata": {
        "id": "gA53idLpPHN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aed54a11-3c42-457d-b4b4-41571a61e21a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 487 µs (started: 2024-09-27 10:18:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify the process_all_files function\n",
        "def process_all_files(folder_path):\n",
        "    results = {}\n",
        "    csv_files = get_csv_files(folder_path)\n",
        "\n",
        "    for file in csv_files:\n",
        "        print(f\"*********************************     Processing {file}...     *********************************\")\n",
        "\n",
        "        # Load and preprocess data\n",
        "        stock_df = pd.read_csv(file)\n",
        "        stock_df = stock_df[['high', 'low', 'open', 'close', 'volume']]\n",
        "        stock_df['volume'] = stock_df['volume'].astype('float64')\n",
        "        stock_df = calculate_technical_indicators(stock_df, normalise=False)\n",
        "\n",
        "        # Prepare data\n",
        "        X_train, y_train, X_test, y_test, test_data = prepare_train_test_data(stock_df, days_input, days_output, train_split, normalise=True, shuffle=True)\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        X_train = torch.from_numpy(X_train).double()\n",
        "        y_train = torch.from_numpy(y_train).double()\n",
        "        X_test = torch.from_numpy(X_test).double()\n",
        "        y_test = torch.from_numpy(y_test).double()\n",
        "\n",
        "        # Prepare datasets\n",
        "        train_size = int(training_size * len(X_train))\n",
        "        train_dataset = (X_train[:train_size, :, :], y_train[:train_size, :])\n",
        "        val_dataset = (X_train[train_size:, :, :], y_train[train_size:, :])\n",
        "\n",
        "        # Initialize model and optimizer\n",
        "        model = CNNLSTMWithSelfAttentionLNN(input_size, hidden_conv_size, hidden_mlp_size, hidden_lstm_size_1, hidden_lstm_size_2, lstm_layers, output_size, kernel_sizes, seq_len, num_days, batch_size, device, l2_lambda, dropout_rate, num_heads)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
        "\n",
        "        # Create a unique save path for each model\n",
        "        # model_save_path = f'model_{os.path.basename(file)}.pth'\n",
        "        model_save_path = f'model.pth'\n",
        "\n",
        "        # Load existing model if available\n",
        "        if os.path.exists(model_save_path):\n",
        "            print(f\"Loading existing model for {file}...\")\n",
        "            model.load_state_dict(torch.load(model_save_path))\n",
        "        else:\n",
        "            print(f\"Training new model for {file}...\")\n",
        "\n",
        "        # Train model\n",
        "        train_loss, val_loss, matching, matching_shifted = train(model, train_dataset, val_dataset, optimizer, scheduler, epochs=epochs, batch_size=batch_size, device=device, save_path=model_save_path)\n",
        "\n",
        "        results[os.path.basename(file)] = {\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss,\n",
        "            'matching': matching,\n",
        "            'matching_shifted': matching_shifted\n",
        "        }\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSYN02CpLkBK",
        "outputId": "427bdffc-6b3f-4b0c-d146-3da3b027b411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 949 µs (started: 2024-09-27 10:18:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(results, epochs):\n",
        "    num_files = len(results)\n",
        "\n",
        "    # Adjust vertical and horizontal spacing\n",
        "    vertical_spacing = max(0.03, min(0.1, 0.3 / num_files))\n",
        "    horizontal_spacing = 0.02\n",
        "\n",
        "    # Create subplots with more descriptive titles\n",
        "    fig = make_subplots(\n",
        "        rows=num_files, cols=4,\n",
        "        subplot_titles=[\n",
        "            item for file in results.keys() for item in\n",
        "            [f\"{file} - Train Loss\", f\"{file} - Val Loss\",\n",
        "             f\"{file} - Matching %\", f\"{file} - Matching Shifted %\"]\n",
        "        ],\n",
        "        vertical_spacing=vertical_spacing,\n",
        "        horizontal_spacing=horizontal_spacing\n",
        "    )\n",
        "\n",
        "    for row, (file, data) in enumerate(results.items(), start=1):\n",
        "        # Training Loss\n",
        "        fig.add_trace(go.Scatter(x=list(range(1, epochs+1)), y=data['train_loss'],\n",
        "                                 name=f'{file} - Train', mode='lines+markers'), row=row, col=1)\n",
        "\n",
        "        # Validation Loss\n",
        "        fig.add_trace(go.Scatter(x=list(range(1, epochs+1)), y=data['val_loss'],\n",
        "                                 name=f'{file} - Val', mode='lines+markers'), row=row, col=2)\n",
        "\n",
        "        # Matching Elements\n",
        "        fig.add_trace(go.Scatter(x=list(range(1, epochs+1)), y=data['matching'],\n",
        "                                 name=f'{file} - Match', mode='lines+markers'), row=row, col=3)\n",
        "\n",
        "        # Matching Elements (Shifted)\n",
        "        fig.add_trace(go.Scatter(x=list(range(1, epochs+1)), y=data['matching_shifted'],\n",
        "                                 name=f'{file} - Match Shifted', mode='lines+markers'), row=row, col=4)\n",
        "\n",
        "    # Update layout with increased height per subplot and adjusted width\n",
        "    fig.update_layout(\n",
        "        height=250*num_files,  # Increase height per subplot\n",
        "        width=1800,            # Slightly increase overall width\n",
        "        title_text=\"Model Performance Across Different Stocks\",\n",
        "        showlegend=False,\n",
        "        title_x=0.5,           # Center the main title\n",
        "    )\n",
        "\n",
        "    # Update y-axes titles and range\n",
        "    for i in range(1, num_files+1):\n",
        "        fig.update_yaxes(title_text=\"Loss\", row=i, col=1, range=[0, max(results[list(results.keys())[i-1]]['train_loss'])*1.1])\n",
        "        fig.update_yaxes(title_text=\"Loss\", row=i, col=2, range=[0, max(results[list(results.keys())[i-1]]['val_loss'])*1.1])\n",
        "        fig.update_yaxes(title_text=\"Matching %\", row=i, col=3, range=[0, 100])\n",
        "        fig.update_yaxes(title_text=\"Matching %\", row=i, col=4, range=[0, 100])\n",
        "\n",
        "    # Update x-axes titles\n",
        "    for i in range(1, num_files*4+1):\n",
        "        fig.update_xaxes(title_text=\"Epochs\", row=(i-1)//4+1, col=(i-1)%4+1)\n",
        "\n",
        "    # Adjust subplot titles font size and position\n",
        "    for i in fig['layout']['annotations']:\n",
        "        i['font'] = dict(size=10)\n",
        "        i['y'] = i['y'] + 0.03  # Move subplot titles up slightly\n",
        "\n",
        "    fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q653m4xoLsjh",
        "outputId": "18077006-3bf2-4fae-9e03-f783c6e3926f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.21 ms (started: 2024-09-27 10:18:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####### DATA LOADING #######\n",
        "\n",
        "file_name = '/content/AMZN_data.csv'            # File name\n",
        "normalise = True               # Whether to normalise or not\n",
        "\n",
        "# Load the data\n",
        "stock_df = pd.read_csv(file_name)\n",
        "stock_df = stock_df[['high', 'low', 'open', 'close', 'volume']]\n",
        "stock_df['volume'] = stock_df['volume'].astype('float64')\n",
        "\n",
        "# Calculate technical indicators\n",
        "stock_df = calculate_technical_indicators(stock_df, normalise)\n",
        "# stock_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMCvp1j_Tlt_",
        "outputId": "75bbbad6-4137-4380-930b-69ff1da9ee76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 10.4 ms (started: 2024-09-27 10:18:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####### DATASET GENERATION #######\n",
        "\n",
        "days_input = 90              # Number of previous data points to use as input\n",
        "days_output = 1              # Number of days to predict\n",
        "train_split = 0.7            # Percentage of data to use for training\n",
        "normalise = False            # Whether to normalise or not\n",
        "shuffle = True               # To Shuffle or not to Shuffle\n",
        "\n",
        "# Preprocess the data\n",
        "X_train, y_train, X_test, y_test, test_data = prepare_train_test_data(stock_df, days_input, days_output, train_split, normalise, shuffle)\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train = torch.from_numpy(X_train).double()\n",
        "y_train = torch.from_numpy(y_train).double()\n",
        "X_test = torch.from_numpy(X_test).double()\n",
        "y_test = torch.from_numpy(y_test).double()\n",
        "\n",
        "# Printing the shapes\n",
        "print(f\"X_train shape : {X_train.shape}\")\n",
        "print(f\"y_train shape : {y_train.shape}\")\n",
        "print(f\"X_test shape : {X_test.shape}\")\n",
        "print(f\"y_test shape : {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0i5iYiFiutSX",
        "outputId": "504061c5-d819-4b69-f067-65d89d8083b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape : torch.Size([775, 90, 18])\n",
            "y_train shape : torch.Size([775, 1])\n",
            "X_test shape : torch.Size([281, 90, 18])\n",
            "y_test shape : torch.Size([281, 1])\n",
            "time: 64.8 ms (started: 2024-09-27 10:18:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####### DATASET PARAMS #######\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "training_size = 0.8                         # Ratio of Training Data\n",
        "validation_size = 0.2                       # Ratio of Validation Data\n",
        "train_size = int(training_size * len(X_train))\n",
        "val_size = int(training_size * len(X_train))\n",
        "\n",
        "# Preparing the training, validation and testing sets\n",
        "train_dataset = (X_train[:train_size, :, :], y_train[:train_size, :])\n",
        "val_dataset = (X_train[train_size:, :, :], y_train[train_size:, :])\n",
        "test_dataset = (X_test, y_test)\n",
        "\n",
        "# Printing the shapes\n",
        "print(f\"training dataset shape : {X_train[:train_size, :, :].shape}\")\n",
        "print(f\"validation dataset shape : {X_train[train_size:].shape}\")\n",
        "print(f\"testing dataset shape : {X_test[1].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dudfz1w1TjYj",
        "outputId": "8cec8361-577a-4e96-ae8c-62b290e2d4af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training dataset shape : torch.Size([620, 90, 18])\n",
            "validation dataset shape : torch.Size([155, 90, 18])\n",
            "testing dataset shape : torch.Size([90, 18])\n",
            "time: 1.52 ms (started: 2024-09-27 10:18:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####### MODEL PARAMS #######\n",
        "\n",
        "# Initialize the model parameters\n",
        "input_size = X_train.shape[-1]                # Number of features in your dataset\n",
        "hidden_conv_size = 512                         # Hidden features after convolution\n",
        "hidden_mlp_size = 1024                       # Hidden features after MLP\n",
        "hidden_lstm_size_1 = 1024                       # Hidden features for self-attention\n",
        "hidden_lstm_size_2 = 1024                       # Hidden features for self-attention\n",
        "lstm_layers = 7                               # Number of LSTM\\GRU layers\n",
        "output_size = 1                               # Output size is 1 for single-value regression\n",
        "kernel_sizes = np.array([2, 3, 5, 7, 14, 21])# Kernel sizes for the convolutional layers\n",
        "seq_len = days_input                          # Sequence length for the LSTM\n",
        "num_days = days_output                        # Number of days predicted\n",
        "dropout_rate = 0.4                            # Dropout rate\n",
        "num_heads = 16                                 # Number of attention heads\n",
        "\n",
        "# Check if the hidden_lstm_size is divisible by num_heads\n",
        "assert hidden_lstm_size_2 % num_heads == 0, \"hidden_lstm_size must be divisible by num_heads\"\n",
        "\n",
        "# Initialize the traning hyperparameters\n",
        "epochs = 20                                      # Number of epochs\n",
        "batch_size = 64                              # Batch size\n",
        "learning_rate = 0.001                           # Learning rate\n",
        "l2_lambda = 0.0001                              # L2 regularisationn\n",
        "save_path = '/content/model.pth'                         # Path to save the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "oz0eKpzZtMjY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3423c1a-ce6c-4890-faa9-31ac28212d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 702 µs (started: 2024-09-27 10:18:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add this at the end of the script\n",
        "folder_path = '/content/'  # Replace with the actual path to your CSV folder\n",
        "results = process_all_files(folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaHz_HG_M8LF",
        "outputId": "3d3db0e3-cdcd-45af-bfd3-02d7b28e844a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*********************************     Processing /content/AMZN_data.csv...     *********************************\n",
            "Training new model for /content/AMZN_data.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 9/9 [00:11<00:00,  1.30s/batch, loss=33]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating...\n",
            "Epoch 1, Training Loss: 33.02957380480237, Validation Loss: 0.9264729022979736\n",
            "\n",
            "Test Loss: 0.9264729022979736\n",
            "Best model saved with validation loss: 0.9265\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 9/9 [00:12<00:00,  1.34s/batch, loss=0.656]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating...\n",
            "Epoch 2, Training Loss: 0.6557608313030667, Validation Loss: 0.5084091126918793\n",
            "\n",
            "Test Loss: 0.5084091126918793\n",
            "Best model saved with validation loss: 0.5084\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 9/9 [00:11<00:00,  1.31s/batch, loss=0.528]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating...\n",
            "Epoch 3, Training Loss: 0.5275431242254045, Validation Loss: 0.9426371455192566\n",
            "\n",
            "Test Loss: 0.9426371455192566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 9/9 [00:11<00:00,  1.28s/batch, loss=0.449]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating...\n",
            "Epoch 4, Training Loss: 0.4491475754313999, Validation Loss: 0.1606251373887062\n",
            "\n",
            "Test Loss: 0.1606251373887062\n",
            "Best model saved with validation loss: 0.1606\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 9/9 [00:11<00:00,  1.26s/batch, loss=0.24]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating...\n",
            "Epoch 5, Training Loss: 0.24042370253139073, Validation Loss: 0.31371499598026276\n",
            "\n",
            "Test Loss: 0.31371499598026276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 9/9 [00:11<00:00,  1.27s/batch, loss=0.246]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating...\n",
            "Epoch 6, Training Loss: 0.245983416835467, Validation Loss: 0.4320816099643707\n",
            "\n",
            "Test Loss: 0.4320816099643707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 9/9 [00:11<00:00,  1.28s/batch, loss=0.217]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating...\n",
            "Epoch 7, Training Loss: 0.21730811480018827, Validation Loss: 0.4939430207014084\n",
            "\n",
            "Test Loss: 0.4939430207014084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 9/9 [00:11<00:00,  1.29s/batch, loss=0.208]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating...\n",
            "Epoch 8, Training Loss: 0.20835461715857187, Validation Loss: 0.427009254693985\n",
            "\n",
            "Test Loss: 0.427009254693985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 9/9 [00:11<00:00,  1.29s/batch, loss=0.203]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating...\n",
            "Epoch 9, Training Loss: 0.20347229639689127, Validation Loss: 0.35324549674987793\n",
            "\n",
            "Test Loss: 0.35324549674987793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 9/9 [00:11<00:00,  1.28s/batch, loss=0.219]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating...\n",
            "Epoch 10, Training Loss: 0.21902389327685037, Validation Loss: 0.34586119651794434\n",
            "\n",
            "Test Loss: 0.34586119651794434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 9/9 [00:11<00:00,  1.28s/batch, loss=0.242]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating...\n",
            "Epoch 11, Training Loss: 0.24202283720175424, Validation Loss: 0.3687480241060257\n",
            "\n",
            "Test Loss: 0.3687480241060257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 9/9 [00:11<00:00,  1.28s/batch, loss=0.244]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating...\n",
            "Epoch 12, Training Loss: 0.24418938987784916, Validation Loss: 0.34518806636333466\n",
            "\n",
            "Test Loss: 0.34518806636333466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 9/9 [00:11<00:00,  1.28s/batch, loss=0.249]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating...\n",
            "Epoch 13, Training Loss: 0.24880373312367332, Validation Loss: 0.30314384400844574\n",
            "\n",
            "Test Loss: 0.30314384400844574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 9/9 [00:11<00:00,  1.28s/batch, loss=0.253]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating...\n",
            "Epoch 14, Training Loss: 0.2532690200540755, Validation Loss: 0.29700706899166107\n",
            "\n",
            "Test Loss: 0.29700706899166107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 9/9 [00:11<00:00,  1.28s/batch, loss=0.265]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating...\n",
            "Epoch 15, Training Loss: 0.2650040884812673, Validation Loss: 0.28171582520008087\n",
            "\n",
            "Test Loss: 0.28171582520008087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 9/9 [00:11<00:00,  1.28s/batch, loss=0.251]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating...\n",
            "Epoch 16, Training Loss: 0.2506753553946813, Validation Loss: 0.2605963349342346\n",
            "\n",
            "Test Loss: 0.2605963349342346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 9/9 [00:11<00:00,  1.28s/batch, loss=0.262]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating...\n",
            "Epoch 17, Training Loss: 0.26248198913203347, Validation Loss: 0.2740979343652725\n",
            "\n",
            "Test Loss: 0.2740979343652725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 9/9 [00:11<00:00,  1.28s/batch, loss=0.261]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating...\n",
            "Epoch 18, Training Loss: 0.26099471085601383, Validation Loss: 0.271465465426445\n",
            "\n",
            "Test Loss: 0.271465465426445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 9/9 [00:11<00:00,  1.28s/batch, loss=0.252]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating...\n",
            "Epoch 19, Training Loss: 0.2517640110519197, Validation Loss: 0.2706739231944084\n",
            "\n",
            "Test Loss: 0.2706739231944084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 9/9 [00:11<00:00,  1.28s/batch, loss=0.253]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating...\n",
            "Epoch 20, Training Loss: 0.2530730929639604, Validation Loss: 0.27109578251838684\n",
            "\n",
            "Test Loss: 0.27109578251838684\n",
            "time: 4min 31s (started: 2024-09-27 10:18:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_results(results, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "xA6CL4Upd2_8",
        "outputId": "9ac57a67-069b-41f4-c0c4-ff5dd97fc313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"ee751493-e020-47df-9ec8-8b525e23b15d\" class=\"plotly-graph-div\" style=\"height:250px; width:1800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ee751493-e020-47df-9ec8-8b525e23b15d\")) {                    Plotly.newPlot(                        \"ee751493-e020-47df-9ec8-8b525e23b15d\",                        [{\"mode\":\"lines+markers\",\"name\":\"AMZN_data.csv - Train\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\"y\":[33.02957380480237,0.6557608313030667,0.5275431242254045,0.4491475754313999,0.24042370253139073,0.245983416835467,0.21730811480018827,0.20835461715857187,0.20347229639689127,0.21902389327685037,0.24202283720175424,0.24418938987784916,0.24880373312367332,0.2532690200540755,0.2650040884812673,0.2506753553946813,0.26248198913203347,0.26099471085601383,0.2517640110519197,0.2530730929639604],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines+markers\",\"name\":\"AMZN_data.csv - Val\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\"y\":[0.9264729022979736,0.5084091126918793,0.9426371455192566,0.1606251373887062,0.31371499598026276,0.4320816099643707,0.4939430207014084,0.427009254693985,0.35324549674987793,0.34586119651794434,0.3687480241060257,0.34518806636333466,0.30314384400844574,0.29700706899166107,0.28171582520008087,0.2605963349342346,0.2740979343652725,0.271465465426445,0.2706739231944084,0.27109578251838684],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"mode\":\"lines+markers\",\"name\":\"AMZN_data.csv - Match\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\"y\":[53.125,23.4375,18.75,54.6875,54.6875,65.625,59.375,64.0625,70.3125,64.0625,75.0,76.5625,82.8125,73.4375,75.0,71.875,71.875,70.3125,70.3125,70.3125],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"mode\":\"lines+markers\",\"name\":\"AMZN_data.csv - Match Shifted\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\"y\":[48.4375,64.0625,70.3125,48.4375,51.5625,37.5,50.0,45.3125,39.0625,48.4375,34.375,34.375,32.8125,37.5,35.9375,42.1875,42.1875,43.75,43.75,43.75],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.235],\"title\":{\"text\":\"Epochs\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loss\"},\"range\":[0,36.332531185282605]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.255,0.49],\"title\":{\"text\":\"Epochs\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loss\"},\"range\":[0,1.0369008600711824]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.51,0.745],\"title\":{\"text\":\"Epochs\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Matching %\"},\"range\":[0,100]},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.7649999999999999,0.9999999999999999],\"title\":{\"text\":\"Epochs\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Matching %\"},\"range\":[0,100]},\"annotations\":[{\"font\":{\"size\":10},\"showarrow\":false,\"text\":\"AMZN_data.csv - Train Loss\",\"x\":0.1175,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.03,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":10},\"showarrow\":false,\"text\":\"AMZN_data.csv - Val Loss\",\"x\":0.3725,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.03,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":10},\"showarrow\":false,\"text\":\"AMZN_data.csv - Matching %\",\"x\":0.6275,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.03,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":10},\"showarrow\":false,\"text\":\"AMZN_data.csv - Matching Shifted %\",\"x\":0.8824999999999998,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.03,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Model Performance Across Different Stocks\",\"x\":0.5},\"height\":250,\"width\":1800,\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ee751493-e020-47df-9ec8-8b525e23b15d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 43.6 ms (started: 2024-09-27 10:22:58 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NCWlwkMz4X4x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b39a16f-0f89-4f89-fee1-a62de4e920a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 50.6 ms (started: 2024-09-27 10:22:58 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####### MODEL INITIALISATION #######\n",
        "\n",
        "# Initialising the model\n",
        "model = CNNLSTMWithSelfAttentionLNN(input_size, hidden_conv_size, hidden_mlp_size, hidden_lstm_size_1, hidden_lstm_size_2, lstm_layers, output_size, kernel_sizes, seq_len, num_days, batch_size, device, l2_lambda, dropout_rate, num_heads)\n",
        "\n",
        "# Defining the optimiser\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Defining the LR scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
        "\n",
        "# Printing the model\n",
        "print(f\"**************** BACKBONE OF THE MODEL **************** \\n\\n {model}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a064wyqpTJxK",
        "outputId": "aa3b8147-ddcf-4cdb-9c0b-bab85abd0eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************** BACKBONE OF THE MODEL **************** \n",
            "\n",
            " CNNLSTMWithSelfAttentionLNN(\n",
            "  (conv_blocks): ConvBlock(\n",
            "    (conv_layers): ModuleList(\n",
            "      (0): Conv1d(18, 512, kernel_size=(2,), stride=(1,), padding=same)\n",
            "      (1): Conv1d(18, 512, kernel_size=(3,), stride=(1,), padding=same)\n",
            "      (2): Conv1d(18, 512, kernel_size=(5,), stride=(1,), padding=same)\n",
            "      (3): Conv1d(18, 512, kernel_size=(7,), stride=(1,), padding=same)\n",
            "      (4): Conv1d(18, 512, kernel_size=(14,), stride=(1,), padding=same)\n",
            "      (5): Conv1d(18, 512, kernel_size=(21,), stride=(1,), padding=same)\n",
            "    )\n",
            "    (bn_layers): ModuleList(\n",
            "      (0-5): 6 x BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (pos_encoder): PositionalEncodingCNN(\n",
            "      (dropout): Dropout(p=0.4, inplace=False)\n",
            "    )\n",
            "    (mlp): Conv1d(3073, 1024, kernel_size=(1,), stride=(1,))\n",
            "    (bn_final): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (activation): ReLU()\n",
            "  )\n",
            "  (lstm_block): TransformerWithAttention(\n",
            "    (input_embedding): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (positional_encoding): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.4, inplace=False)\n",
            "    )\n",
            "    (transformer_encoders): ModuleList(\n",
            "      (0-2): 3 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (dropout): Dropout(p=0.4, inplace=False)\n",
            "        (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.4, inplace=False)\n",
            "        (dropout2): Dropout(p=0.4, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (self_attentions): ModuleList(\n",
            "      (0-1): 2 x SelfAttention(\n",
            "        (mha): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (multihead_attentions): ModuleList(\n",
            "      (0-4): 5 x MultiheadAttention(\n",
            "        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (transformer_decoders): ModuleList(\n",
            "      (0-2): 3 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (multihead_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (dropout): Dropout(p=0.4, inplace=False)\n",
            "        (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.4, inplace=False)\n",
            "        (dropout2): Dropout(p=0.4, inplace=False)\n",
            "        (dropout3): Dropout(p=0.4, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (cross_attentions): ModuleList(\n",
            "      (0-1): 2 x CrossAttention(\n",
            "        (mha): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (norm_hidden): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (norm_output): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.4, inplace=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=1024, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.4, inplace=False)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "time: 999 ms (started: 2024-09-27 10:22:58 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load the model if saved\n",
        "# if os.path.isfile(save_path):\n",
        "#   print(\"Saved model loaded...\\n\")\n",
        "#   model.load_state_dict(torch.load(save_path))\n",
        "\n",
        "# # Train the model\n",
        "# train_loss, val_loss = train(model, train_dataset, val_dataset, optimizer, scheduler, epochs=epochs, batch_size=batch_size, device=device, save_path=save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH_UuR8pu4MA",
        "outputId": "e15f3186-9c5b-465a-9c22-6f142726cd43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 303 µs (started: 2024-09-27 10:22:59 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create the plot\n",
        "# fig = go.Figure()\n",
        "\n",
        "# # Add training loss trace\n",
        "# fig.add_trace(go.Scatter(\n",
        "#     x=np.arange(len(train_loss)),\n",
        "#     y=train_loss,\n",
        "#     mode='lines+markers',\n",
        "#     name='Training Loss'\n",
        "# ))\n",
        "\n",
        "# # Add validation loss trace\n",
        "# fig.add_trace(go.Scatter(\n",
        "#     x=np.arange(len(val_loss)),\n",
        "#     y=val_loss,\n",
        "#     mode='lines+markers',\n",
        "#     name='Validation Loss'\n",
        "# ))\n",
        "\n",
        "# # Update layout\n",
        "# fig.update_layout(\n",
        "#     title='Training and Validation Loss Over Epochs',\n",
        "#     xaxis_title='Epoch',\n",
        "#     yaxis_title='Loss',\n",
        "#     legend_title='Loss Type',\n",
        "#     template='plotly_dark'\n",
        "# )\n",
        "\n",
        "# # Show the plot\n",
        "# fig.show()"
      ],
      "metadata": {
        "id": "9b8fP6egBqHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1a36153-ca17-43cd-c4bc-f88171e0e131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 279 µs (started: 2024-09-27 10:22:59 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the model if saved\n",
        "if os.path.isfile(save_path):\n",
        "  print(\"Saved model loaded...\\n\\n\")\n",
        "  model.load_state_dict(torch.load(save_path))\n",
        "\n",
        "# # Reset hidden states before testing\n",
        "# model.reset_hidden()\n",
        "\n",
        "# Test the model\n",
        "test_loss, outputs, labels = test(model, test_dataset, batch_size, device)"
      ],
      "metadata": {
        "id": "zNq7mU4pUlVf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12b69984-8b98-42ac-857e-787512aff898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model loaded...\n",
            "\n",
            "\n",
            "Test Loss: 4.413557648658752\n",
            "time: 2.14 s (started: 2024-09-27 10:22:59 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.shape)\n",
        "print(labels.shape)"
      ],
      "metadata": {
        "id": "89VEcxcRcUkI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4f1bd24-9dfa-4ba3-a19f-3279f450a30c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1])\n",
            "torch.Size([64, 1])\n",
            "time: 533 µs (started: 2024-09-27 10:23:01 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs)"
      ],
      "metadata": {
        "id": "rj8sS3mFx3lO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "033505f0-5ce2-4229-e5bf-a286555e6efe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.8070],\n",
            "        [-0.8074],\n",
            "        [-0.8072],\n",
            "        [-0.8071],\n",
            "        [-0.8072],\n",
            "        [-0.8069],\n",
            "        [-0.8071],\n",
            "        [-0.8071],\n",
            "        [-0.8073],\n",
            "        [-0.8072],\n",
            "        [-0.8072],\n",
            "        [-0.8075],\n",
            "        [-0.8074],\n",
            "        [-0.8072],\n",
            "        [-0.8072],\n",
            "        [-0.8070],\n",
            "        [-0.8072],\n",
            "        [-0.8071],\n",
            "        [-0.8070],\n",
            "        [-0.8072],\n",
            "        [-0.8071],\n",
            "        [-0.8072],\n",
            "        [-0.8071],\n",
            "        [-0.8072],\n",
            "        [-0.8071],\n",
            "        [-0.8072],\n",
            "        [-0.8071],\n",
            "        [-0.8072],\n",
            "        [-0.8071],\n",
            "        [-0.8072],\n",
            "        [-0.8073],\n",
            "        [-0.8074],\n",
            "        [-0.8073],\n",
            "        [-0.8073],\n",
            "        [-0.8072],\n",
            "        [-0.8073],\n",
            "        [-0.8072],\n",
            "        [-0.8072],\n",
            "        [-0.8073],\n",
            "        [-0.8072],\n",
            "        [-0.8073],\n",
            "        [-0.8072],\n",
            "        [-0.8074],\n",
            "        [-0.8071],\n",
            "        [-0.8073],\n",
            "        [-0.8071],\n",
            "        [-0.8073],\n",
            "        [-0.8072],\n",
            "        [-0.8072],\n",
            "        [-0.8072],\n",
            "        [-0.8074],\n",
            "        [-0.8072],\n",
            "        [-0.8075],\n",
            "        [-0.8071],\n",
            "        [-0.8072],\n",
            "        [-0.8070],\n",
            "        [-0.8072],\n",
            "        [-0.8070],\n",
            "        [-0.8072],\n",
            "        [-0.8069],\n",
            "        [-0.8074],\n",
            "        [-0.8072],\n",
            "        [-0.8072],\n",
            "        [-0.8071]], device='cuda:0')\n",
            "time: 6.43 ms (started: 2024-09-27 10:23:01 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels)"
      ],
      "metadata": {
        "id": "tXK6kzqi79eR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db592be7-c28b-438a-d212-136be0ddb424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.3538],\n",
            "        [1.3464],\n",
            "        [1.3760],\n",
            "        [1.4305],\n",
            "        [1.4615],\n",
            "        [1.4665],\n",
            "        [1.4530],\n",
            "        [1.4807],\n",
            "        [1.5017],\n",
            "        [1.5088],\n",
            "        [1.5208],\n",
            "        [1.5307],\n",
            "        [1.4877],\n",
            "        [1.4509],\n",
            "        [1.4378],\n",
            "        [1.3790],\n",
            "        [1.4130],\n",
            "        [1.4024],\n",
            "        [1.4007],\n",
            "        [1.8558],\n",
            "        [1.8909],\n",
            "        [1.8712],\n",
            "        [1.8655],\n",
            "        [1.8320],\n",
            "        [1.8936],\n",
            "        [1.9256],\n",
            "        [1.9345],\n",
            "        [1.9689],\n",
            "        [1.9556],\n",
            "        [1.9423],\n",
            "        [1.9558],\n",
            "        [1.9829],\n",
            "        [1.9470],\n",
            "        [1.9845],\n",
            "        [1.9583],\n",
            "        [1.9457],\n",
            "        [1.9923],\n",
            "        [2.0514],\n",
            "        [2.1570],\n",
            "        [2.1918],\n",
            "        [2.1839],\n",
            "        [2.0695],\n",
            "        [2.1243],\n",
            "        [2.0733],\n",
            "        [1.9727],\n",
            "        [1.9997],\n",
            "        [2.0379],\n",
            "        [2.0642],\n",
            "        [2.0720],\n",
            "        [2.0965],\n",
            "        [2.0829],\n",
            "        [2.0796],\n",
            "        [2.1155],\n",
            "        [2.1327],\n",
            "        [2.1732],\n",
            "        [2.1619],\n",
            "        [2.1274],\n",
            "        [2.1172],\n",
            "        [2.0946],\n",
            "        [2.1243],\n",
            "        [2.1438],\n",
            "        [2.1574],\n",
            "        [2.0985],\n",
            "        [2.1677]], device='cuda:0')\n",
            "time: 6.03 ms (started: 2024-09-27 10:23:01 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert tensors to numpy arrays\n",
        "outputs_np = outputs.cpu().numpy()\n",
        "labels_np = labels.cpu().numpy()\n",
        "\n",
        "# Extract the entire arrays (no need to get the first value as the size is already [929, 1])\n",
        "outputs_np = outputs_np.flatten()\n",
        "labels_np = labels_np.flatten()\n",
        "\n",
        "print(outputs_np.shape)\n",
        "print(labels_np.shape)\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "# Plot using Plotly\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(labels_np)), y=labels_np, mode='lines', name='Label'))\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(outputs_np)), y=outputs_np, mode='lines', name='Output'))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Labels and Outputs',\n",
        "    xaxis_title='Index',\n",
        "    yaxis_title='Value',\n",
        "    legend_title='Legend'\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "OB0S9l5vcN-c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "ec8d88fb-1516-4d32-b9c3-424d96ae5724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64,)\n",
            "(64,)\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"081b793d-a6a5-48da-ad5b-03f49f008558\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"081b793d-a6a5-48da-ad5b-03f49f008558\")) {                    Plotly.newPlot(                        \"081b793d-a6a5-48da-ad5b-03f49f008558\",                        [{\"mode\":\"lines\",\"name\":\"Label\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63],\"y\":[1.353845477104187,1.3464443683624268,1.3760135173797607,1.4305484294891357,1.4614633321762085,1.466456413269043,1.4530352354049683,1.4806567430496216,1.501656174659729,1.5087740421295166,1.5208141803741455,1.5306942462921143,1.4877392053604126,1.4509458541870117,1.4378433227539062,1.379023551940918,1.4130192995071411,1.4024311304092407,1.4007313251495361,1.8558495044708252,1.890907645225525,1.8711830377578735,1.865517020225525,1.8320170640945435,1.8935635089874268,1.9256470203399658,1.9345355033874512,1.9689208269119263,1.9556411504745483,1.9422553777694702,1.9557828903198242,1.9829440116882324,1.9470006227493286,1.9845376014709473,1.9582971334457397,1.9456549882888794,1.9923282861709595,2.051360607147217,2.1570305824279785,2.191840887069702,2.1839439868927,2.069456100463867,2.124274253845215,2.0732805728912354,1.9727098941802979,1.9996939897537231,2.0378684997558594,2.0642151832580566,2.0720412731170654,2.0965464115142822,2.0829482078552246,2.0795841217041016,2.1154565811157227,2.132737874984741,2.1732494831085205,2.1619174480438232,2.1273550987243652,2.11722731590271,2.0945634841918945,2.124309778213501,2.1437864303588867,2.1573848724365234,2.098494291305542,2.167689800262451],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Output\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63],\"y\":[-0.8070067763328552,-0.8073633313179016,-0.8071519732475281,-0.8071165084838867,-0.80716472864151,-0.8069170117378235,-0.8070553541183472,-0.8070581555366516,-0.8072763085365295,-0.8071528673171997,-0.8071755766868591,-0.8074758648872375,-0.8073660731315613,-0.8071885108947754,-0.8071510791778564,-0.8069561123847961,-0.8071828484535217,-0.8071420788764954,-0.806954562664032,-0.8072177767753601,-0.8071367144584656,-0.8071509003639221,-0.8071333765983582,-0.8071653246879578,-0.8071403503417969,-0.8071895241737366,-0.8071321845054626,-0.8072093725204468,-0.8071476817131042,-0.8072457909584045,-0.8072735071182251,-0.8073554635047913,-0.8072545528411865,-0.8072779178619385,-0.8072364926338196,-0.8072556257247925,-0.8072375655174255,-0.807199239730835,-0.8072916269302368,-0.8071953058242798,-0.8072558045387268,-0.807161271572113,-0.8074364066123962,-0.8071414828300476,-0.8073312044143677,-0.8071356415748596,-0.807272732257843,-0.8071850538253784,-0.8072414994239807,-0.80722975730896,-0.8074484467506409,-0.8072292804718018,-0.8074607253074646,-0.8071113228797913,-0.807181179523468,-0.8070144057273865,-0.8072221875190735,-0.8070178627967834,-0.8071958422660828,-0.8069482445716858,-0.8074012398719788,-0.8072233200073242,-0.8072386384010315,-0.8070704340934753],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Labels and Outputs\"},\"xaxis\":{\"title\":{\"text\":\"Index\"}},\"yaxis\":{\"title\":{\"text\":\"Value\"}},\"legend\":{\"title\":{\"text\":\"Legend\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('081b793d-a6a5-48da-ad5b-03f49f008558');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 12.9 ms (started: 2024-09-27 10:23:01 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array_output = assign_trend_sign(outputs_np)\n",
        "array_labels = assign_trend_sign(labels_np)\n",
        "\n",
        "matching_val = count_matching_elements(array_output, array_labels)\n",
        "print(f\"Matching elements precentage: {matching_val}\")"
      ],
      "metadata": {
        "id": "0Pkeb9HsbwWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a79cad7b-c350-4d29-b598-69686fc60bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matching elements precentage: 46.875\n",
            "time: 706 µs (started: 2024-09-27 10:23:01 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(array_output)"
      ],
      "metadata": {
        "id": "VT4oOgaW6idF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1c690f-8255-4081-b364-f93c08237025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0. -1.  1.  1. -1.  1. -1. -1. -1.  1. -1. -1.  1.  1.  1.  1. -1.  1.\n",
            "  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1. -1. -1.  1. -1.  1. -1.\n",
            "  1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1.\n",
            " -1.  1. -1.  1. -1.  1. -1.  1. -1.  1.]\n",
            "time: 845 µs (started: 2024-09-27 10:23:01 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(array_labels)"
      ],
      "metadata": {
        "id": "gPmxENBi7OcW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23193404-d168-42ca-94cd-74c63a9bcbd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1.  1. -1.\n",
            " -1.  1.  1. -1. -1. -1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.\n",
            "  1.  1.  1.  1. -1. -1.  1. -1. -1.  1.  1.  1.  1.  1. -1. -1.  1.  1.\n",
            "  1. -1. -1. -1. -1.  1.  1.  1. -1.  1.]\n",
            "time: 896 µs (started: 2024-09-27 10:23:01 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot using Plotly\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(array_labels)), y=array_labels, mode='lines', name='Label'))\n",
        "fig.add_trace(go.Scatter(x=np.arange(len(array_output)), y=array_output, mode='lines', name='Output'))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Labels and Outputs',\n",
        "    xaxis_title='Index',\n",
        "    yaxis_title='Value',\n",
        "    legend_title='Legend'\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "vnb9Ecue8p5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "outputId": "38f71f2f-9a5d-4653-f588-d3f308dbc1b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"409c9c2b-fb35-4382-9d1c-f59c5467d516\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"409c9c2b-fb35-4382-9d1c-f59c5467d516\")) {                    Plotly.newPlot(                        \"409c9c2b-fb35-4382-9d1c-f59c5467d516\",                        [{\"mode\":\"lines\",\"name\":\"Label\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63],\"y\":[0.0,-1.0,1.0,1.0,1.0,1.0,-1.0,1.0,1.0,1.0,1.0,1.0,-1.0,-1.0,-1.0,-1.0,1.0,-1.0,-1.0,1.0,1.0,-1.0,-1.0,-1.0,1.0,1.0,1.0,1.0,-1.0,-1.0,1.0,1.0,-1.0,1.0,-1.0,-1.0,1.0,1.0,1.0,1.0,-1.0,-1.0,1.0,-1.0,-1.0,1.0,1.0,1.0,1.0,1.0,-1.0,-1.0,1.0,1.0,1.0,-1.0,-1.0,-1.0,-1.0,1.0,1.0,1.0,-1.0,1.0],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Output\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63],\"y\":[0.0,-1.0,1.0,1.0,-1.0,1.0,-1.0,-1.0,-1.0,1.0,-1.0,-1.0,1.0,1.0,1.0,1.0,-1.0,1.0,1.0,-1.0,1.0,-1.0,1.0,-1.0,1.0,-1.0,1.0,-1.0,1.0,-1.0,-1.0,-1.0,1.0,-1.0,1.0,-1.0,1.0,1.0,-1.0,1.0,-1.0,1.0,-1.0,1.0,-1.0,1.0,-1.0,1.0,-1.0,1.0,-1.0,1.0,-1.0,1.0,-1.0,1.0,-1.0,1.0,-1.0,1.0,-1.0,1.0,-1.0,1.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Labels and Outputs\"},\"xaxis\":{\"title\":{\"text\":\"Index\"}},\"yaxis\":{\"title\":{\"text\":\"Value\"}},\"legend\":{\"title\":{\"text\":\"Legend\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('409c9c2b-fb35-4382-9d1c-f59c5467d516');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 14.3 ms (started: 2024-09-27 10:23:01 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming array_output and array_labels are already defined and are 1D numpy arrays\n",
        "# containing the trend signs (-1, 0, 1) for each element in the sequence\n",
        "#. t\\o  -1  0  1\n",
        "#.  -1\n",
        "#.   0\n",
        "#.   1\n",
        "\n",
        "# Compute the confusion matrix\n",
        "conf_matrix = confusion_matrix(array_labels, array_output)\n",
        "\n",
        "print(f\"Confusion Matrix: \\n{conf_matrix}\")"
      ],
      "metadata": {
        "id": "jyuLHyiZ0IhJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "682b7bf9-ae7d-40d3-d8d8-c32da9e13c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: \n",
            "[[12  0 15]\n",
            " [ 0  1  0]\n",
            " [19  0 17]]\n",
            "time: 3.35 ms (started: 2024-09-27 10:23:01 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array_output = assign_trend_sign(np.roll(outputs_np, -1))\n",
        "array_labels = assign_trend_sign(labels_np)\n",
        "\n",
        "matching_val = count_matching_elements(array_output, array_labels)\n",
        "print(f\"Matching elements precentage if output is shifted: {matching_val}\")"
      ],
      "metadata": {
        "id": "Ecz6EHRT6RkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d09dbb4-31ec-47e7-8eee-da9f322b8c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matching elements precentage if output is shifted: 51.5625\n",
            "time: 1.37 ms (started: 2024-09-27 10:23:01 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Sharpe ratio\n",
        "returns = pd.Series(outputs_np).pct_change().dropna()\n",
        "sharpe_ratio = calculate_sharpe_ratio(returns)\n",
        "print(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")"
      ],
      "metadata": {
        "id": "ACakGjJgMY8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "035eae87-9e94-4c2c-8fe3-930b4da3fdcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sharpe Ratio: -1525.10\n",
            "time: 2.38 ms (started: 2024-09-27 10:23:01 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def trading_strategy(labels, output, initial_balance=10000, share_price=100):\n",
        "    balance = initial_balance  # Starting with some initial balance\n",
        "    shares = 0  # No shares initially\n",
        "    total_profit = 0\n",
        "    spent=0\n",
        "    total_spent=0;\n",
        "    for i in range(len(output)):\n",
        "\n",
        "        if output[i] > 0:  # Predicted profit day\n",
        "            # Buy as many shares as possible\n",
        "            shares_to_buy = 10\n",
        "            shares += shares_to_buy\n",
        "            balance -= shares_to_buy * share_price\n",
        "            spent=10*share_price\n",
        "            print(f\"Day {i}: Bought {shares_to_buy} shares at {share_price} each, Balance: {balance}, Shares: {shares}\")\n",
        "\n",
        "        elif output[i] < 0:  # Predicted loss day\n",
        "            # Sell all shares\n",
        "            balance += shares * share_price\n",
        "            profit = shares * (share_price)-spent\n",
        "            total_spent+= spent\n",
        "\n",
        "            spent=0\n",
        "            total_profit += profit\n",
        "            print(f\"Day {i}: Sold {shares} shares at {share_price} each, Balance: {balance}, Profit: {profit}, Total Profit: {total_profit}\")\n",
        "            shares = 0  # Reset shares after selling\n",
        "        share_price+=labels[i]\n",
        "    # At the end, sell any remaining shares\n",
        "    print(f\"Total Spent {total_spent}\")\n",
        "    if shares > 0:\n",
        "        balance = shares * share_price\n",
        "        print(f\"Final Sale: Sold remaining {shares} shares, Final Balance: {balance}\")\n",
        "\n",
        "    print(f\"Final Total Profit: {total_profit}\")\n",
        "    return total_profit, balance\n",
        "\n",
        "\n",
        "trading_strategy(array_labels, array_output)"
      ],
      "metadata": {
        "id": "aVP8tfvdMQOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0043132b-bc2d-4f64-a096-d89fecd43b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Day 1: Bought 10 shares at 100.0 each, Balance: 9000.0, Shares: 10\n",
            "Day 2: Bought 10 shares at 99.0 each, Balance: 8010.0, Shares: 20\n",
            "Day 3: Sold 20 shares at 100.0 each, Balance: 10010.0, Profit: 1010.0, Total Profit: 1010.0\n",
            "Day 4: Bought 10 shares at 101.0 each, Balance: 9000.0, Shares: 10\n",
            "Day 5: Sold 10 shares at 102.0 each, Balance: 10020.0, Profit: 10.0, Total Profit: 1020.0\n",
            "Day 6: Sold 0 shares at 103.0 each, Balance: 10020.0, Profit: 0.0, Total Profit: 1020.0\n",
            "Day 7: Sold 0 shares at 102.0 each, Balance: 10020.0, Profit: 0.0, Total Profit: 1020.0\n",
            "Day 8: Bought 10 shares at 103.0 each, Balance: 8990.0, Shares: 10\n",
            "Day 9: Sold 10 shares at 104.0 each, Balance: 10030.0, Profit: 10.0, Total Profit: 1030.0\n",
            "Day 10: Sold 0 shares at 105.0 each, Balance: 10030.0, Profit: 0.0, Total Profit: 1030.0\n",
            "Day 11: Bought 10 shares at 106.0 each, Balance: 8970.0, Shares: 10\n",
            "Day 12: Bought 10 shares at 107.0 each, Balance: 7900.0, Shares: 20\n",
            "Day 13: Bought 10 shares at 106.0 each, Balance: 6840.0, Shares: 30\n",
            "Day 14: Bought 10 shares at 105.0 each, Balance: 5790.0, Shares: 40\n",
            "Day 15: Sold 40 shares at 104.0 each, Balance: 9950.0, Profit: 3110.0, Total Profit: 4140.0\n",
            "Day 16: Bought 10 shares at 103.0 each, Balance: 8920.0, Shares: 10\n",
            "Day 17: Bought 10 shares at 104.0 each, Balance: 7880.0, Shares: 20\n",
            "Day 18: Sold 20 shares at 103.0 each, Balance: 9940.0, Profit: 1020.0, Total Profit: 5160.0\n",
            "Day 19: Bought 10 shares at 102.0 each, Balance: 8920.0, Shares: 10\n",
            "Day 20: Sold 10 shares at 103.0 each, Balance: 9950.0, Profit: 10.0, Total Profit: 5170.0\n",
            "Day 21: Bought 10 shares at 104.0 each, Balance: 8910.0, Shares: 10\n",
            "Day 22: Sold 10 shares at 103.0 each, Balance: 9940.0, Profit: -10.0, Total Profit: 5160.0\n",
            "Day 23: Bought 10 shares at 102.0 each, Balance: 8920.0, Shares: 10\n",
            "Day 24: Sold 10 shares at 101.0 each, Balance: 9930.0, Profit: -10.0, Total Profit: 5150.0\n",
            "Day 25: Bought 10 shares at 102.0 each, Balance: 8910.0, Shares: 10\n",
            "Day 26: Sold 10 shares at 103.0 each, Balance: 9940.0, Profit: 10.0, Total Profit: 5160.0\n",
            "Day 27: Bought 10 shares at 104.0 each, Balance: 8900.0, Shares: 10\n",
            "Day 28: Sold 10 shares at 105.0 each, Balance: 9950.0, Profit: 10.0, Total Profit: 5170.0\n",
            "Day 29: Sold 0 shares at 104.0 each, Balance: 9950.0, Profit: 0.0, Total Profit: 5170.0\n",
            "Day 30: Sold 0 shares at 103.0 each, Balance: 9950.0, Profit: 0.0, Total Profit: 5170.0\n",
            "Day 31: Bought 10 shares at 104.0 each, Balance: 8910.0, Shares: 10\n",
            "Day 32: Sold 10 shares at 105.0 each, Balance: 9960.0, Profit: 10.0, Total Profit: 5180.0\n",
            "Day 33: Bought 10 shares at 104.0 each, Balance: 8920.0, Shares: 10\n",
            "Day 34: Sold 10 shares at 105.0 each, Balance: 9970.0, Profit: 10.0, Total Profit: 5190.0\n",
            "Day 35: Bought 10 shares at 104.0 each, Balance: 8930.0, Shares: 10\n",
            "Day 36: Bought 10 shares at 103.0 each, Balance: 7900.0, Shares: 20\n",
            "Day 37: Sold 20 shares at 104.0 each, Balance: 9980.0, Profit: 1050.0, Total Profit: 6240.0\n",
            "Day 38: Bought 10 shares at 105.0 each, Balance: 8930.0, Shares: 10\n",
            "Day 39: Sold 10 shares at 106.0 each, Balance: 9990.0, Profit: 10.0, Total Profit: 6250.0\n",
            "Day 40: Bought 10 shares at 107.0 each, Balance: 8920.0, Shares: 10\n",
            "Day 41: Sold 10 shares at 106.0 each, Balance: 9980.0, Profit: -10.0, Total Profit: 6240.0\n",
            "Day 42: Bought 10 shares at 105.0 each, Balance: 8930.0, Shares: 10\n",
            "Day 43: Sold 10 shares at 106.0 each, Balance: 9990.0, Profit: 10.0, Total Profit: 6250.0\n",
            "Day 44: Bought 10 shares at 105.0 each, Balance: 8940.0, Shares: 10\n",
            "Day 45: Sold 10 shares at 104.0 each, Balance: 9980.0, Profit: -10.0, Total Profit: 6240.0\n",
            "Day 46: Bought 10 shares at 105.0 each, Balance: 8930.0, Shares: 10\n",
            "Day 47: Sold 10 shares at 106.0 each, Balance: 9990.0, Profit: 10.0, Total Profit: 6250.0\n",
            "Day 48: Bought 10 shares at 107.0 each, Balance: 8920.0, Shares: 10\n",
            "Day 49: Sold 10 shares at 108.0 each, Balance: 10000.0, Profit: 10.0, Total Profit: 6260.0\n",
            "Day 50: Bought 10 shares at 109.0 each, Balance: 8910.0, Shares: 10\n",
            "Day 51: Sold 10 shares at 108.0 each, Balance: 9990.0, Profit: -10.0, Total Profit: 6250.0\n",
            "Day 52: Bought 10 shares at 107.0 each, Balance: 8920.0, Shares: 10\n",
            "Day 53: Sold 10 shares at 108.0 each, Balance: 10000.0, Profit: 10.0, Total Profit: 6260.0\n",
            "Day 54: Bought 10 shares at 109.0 each, Balance: 8910.0, Shares: 10\n",
            "Day 55: Sold 10 shares at 110.0 each, Balance: 10010.0, Profit: 10.0, Total Profit: 6270.0\n",
            "Day 56: Bought 10 shares at 109.0 each, Balance: 8920.0, Shares: 10\n",
            "Day 57: Sold 10 shares at 108.0 each, Balance: 10000.0, Profit: -10.0, Total Profit: 6260.0\n",
            "Day 58: Bought 10 shares at 107.0 each, Balance: 8930.0, Shares: 10\n",
            "Day 59: Sold 10 shares at 106.0 each, Balance: 9990.0, Profit: -10.0, Total Profit: 6250.0\n",
            "Day 60: Bought 10 shares at 107.0 each, Balance: 8920.0, Shares: 10\n",
            "Day 61: Sold 10 shares at 108.0 each, Balance: 10000.0, Profit: 10.0, Total Profit: 6260.0\n",
            "Day 62: Bought 10 shares at 109.0 each, Balance: 8910.0, Shares: 10\n",
            "Day 63: Bought 10 shares at 108.0 each, Balance: 7830.0, Shares: 20\n",
            "Total Spent 26190.0\n",
            "Final Sale: Sold remaining 20 shares, Final Balance: 2180.0\n",
            "Final Total Profit: 6260.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6260.0, 2180.0)"
            ]
          },
          "metadata": {},
          "execution_count": 163
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 26.9 ms (started: 2024-09-27 10:23:01 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haDoXMHH36NK",
        "outputId": "7ba6dc51-8dfb-49ff-81af-2afb749bfd14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 33.7 ms (started: 2024-09-27 10:23:01 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def trading_strategy(labels_np, outputs_np, initial_balance=10000):\n",
        "    balance = initial_balance\n",
        "    shares = 0\n",
        "    total_profit = 0\n",
        "    total_spent = 0\n",
        "    share_price = initial_share_price\n",
        "    last_buy_price = 0\n",
        "    last_sell_price = 0\n",
        "    initial_share_price = labels_np[0]\n",
        "\n",
        "    for i in range(1, len(outputs_np)):  # Start from 1 to compare with previous day\n",
        "        # Calculate the delta (change) between current and previous day's predictions\n",
        "        delta = outputs_np[i] - outputs_np[i-1]\n",
        "\n",
        "        # Use actual price from labels for calculations\n",
        "        current_price = share_price + labels_np[i] - labels_np[i-1]\n",
        "\n",
        "        if delta > 0 and balance > 0:  # Buy signal: prediction increased\n",
        "            price_change = (current_price - last_sell_price) / last_sell_price if last_sell_price > 0 else 0\n",
        "            if price_change >= 0:#0.005:  # Only buy if there's a 5% increase from last sell\n",
        "                # Buy as many shares as possible\n",
        "                shares_to_buy = balance // current_price\n",
        "                if shares_to_buy > 0:\n",
        "                    shares += shares_to_buy\n",
        "                    cost = shares_to_buy * current_price\n",
        "                    balance -= cost\n",
        "                    total_spent += cost\n",
        "                    last_buy_price = current_price\n",
        "                    print(f\"Day {i+1}: Bought {shares_to_buy} shares at {current_price:.2f} each, Balance: {balance:.2f}, Shares: {shares}\")\n",
        "\n",
        "        elif delta < 0 and shares > 0:  # Sell signal: prediction decreased\n",
        "            price_change = (last_buy_price - current_price) / last_buy_price if last_buy_price > 0 else 0\n",
        "            if price_change >= 0:#0.005:  # Only sell if there's a 5% decrease from last buy\n",
        "                # Sell all shares\n",
        "                sale_amount = shares * current_price\n",
        "                profit = sale_amount - total_spent\n",
        "                tax = profit * 0.1  # 10% tax on profit\n",
        "                profit_after_tax = profit - tax\n",
        "                balance += sale_amount - tax\n",
        "                total_profit += profit_after_tax\n",
        "                last_sell_price = current_price\n",
        "                print(f\"Day {i+1}: Sold {shares} shares at {current_price:.2f} each, Balance: {balance:.2f}, Profit: {profit_after_tax:.2f}, Tax: {tax:.2f}, Total Profit: {total_profit:.2f}\")\n",
        "                shares = 0\n",
        "                total_spent = 0\n",
        "\n",
        "        # Update share price for the next day\n",
        "        share_price = current_price\n",
        "\n",
        "    # Sell any remaining shares at the end\n",
        "    if shares > 0:\n",
        "        final_sale_amount = shares * share_price\n",
        "        final_profit = final_sale_amount - total_spent\n",
        "        final_tax = final_profit * 0.1\n",
        "        final_profit_after_tax = final_profit - final_tax\n",
        "        total_profit += final_profit_after_tax\n",
        "        balance += final_sale_amount - final_tax\n",
        "        print(f\"Final Sale: Sold remaining {shares} shares at {share_price:.2f}, Final Balance: {balance:.2f}, Final Profit: {final_profit_after_tax:.2f}, Tax: {final_tax:.2f}\")\n",
        "\n",
        "    profit_percentage = (total_profit / initial_balance) * 100\n",
        "    print(f\"Final Total Profit: {total_profit:.2f}\")\n",
        "    print(f\"Profit Percentage: {profit_percentage:.2f}%\")\n",
        "\n",
        "    return total_profit, balance, profit_percentage\n",
        "\n",
        "# Example usage:\n",
        "trading_strategy(labels_np, outputs_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kuf_MnkvdfE0",
        "outputId": "9b729d66-e8e5-4edd-c9ef-52e995c543e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Day 3: Bought 9783.0 shares at 1.02 each, Balance: 0.13, Shares: 9783.0\n",
            "Final Sale: Sold remaining 9783.0 shares at 1.81, Final Balance: 16970.47, Final Profit: 6970.47, Tax: 774.50\n",
            "Final Total Profit: 6970.47\n",
            "Profit Percentage: 69.70%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6970.472167897225, 16970.472167897224, 69.70472167897225)"
            ]
          },
          "metadata": {},
          "execution_count": 172
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8.39 ms (started: 2024-09-27 10:26:22 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvvUKZUQdgfd",
        "outputId": "b877146a-d81c-4b10-aaa6-8f53109d433d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.8070068 , -0.80736333, -0.807152  , -0.8071165 , -0.8071647 ,\n",
              "       -0.806917  , -0.80705535, -0.80705816, -0.8072763 , -0.80715287,\n",
              "       -0.8071756 , -0.80747586, -0.8073661 , -0.8071885 , -0.8071511 ,\n",
              "       -0.8069561 , -0.80718285, -0.8071421 , -0.80695456, -0.8072178 ,\n",
              "       -0.8071367 , -0.8071509 , -0.8071334 , -0.8071653 , -0.80714035,\n",
              "       -0.8071895 , -0.8071322 , -0.8072094 , -0.8071477 , -0.8072458 ,\n",
              "       -0.8072735 , -0.80735546, -0.80725455, -0.8072779 , -0.8072365 ,\n",
              "       -0.8072556 , -0.80723757, -0.80719924, -0.8072916 , -0.8071953 ,\n",
              "       -0.8072558 , -0.8071613 , -0.8074364 , -0.8071415 , -0.8073312 ,\n",
              "       -0.80713564, -0.80727273, -0.80718505, -0.8072415 , -0.80722976,\n",
              "       -0.80744845, -0.8072293 , -0.8074607 , -0.8071113 , -0.8071812 ,\n",
              "       -0.8070144 , -0.8072222 , -0.80701786, -0.80719584, -0.80694824,\n",
              "       -0.80740124, -0.8072233 , -0.80723864, -0.80707043], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 165
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.66 ms (started: 2024-09-27 10:23:01 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x2LZG3w0mGy",
        "outputId": "f817c680-76fd-4829-faba-e3781f558143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8.15 ms (started: 2024-09-27 10:23:01 +00:00)\n"
          ]
        }
      ]
    }
  ]
}